{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd729ea-b8e2-4f2c-b1ab-345058b2ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing file checks ...\n",
      "Process 1 is handling the following tasks: ['ade_classification.py', 'agnews.py', 'amazon_polarity.py', 'anli.py', 'circa.py']\n",
      "Process 2 is handling the following tasks: ['climate_fever.py', 'dbpedia_14.py', 'discovery.py', 'emo.py', 'emotion.py']\n",
      "Process 1: Processing ade_classification.py ...\n",
      "Process 2: Processing climate_fever.py ...\n",
      "Process 3 is handling the following tasks: ['empathetic_dialogues.py', 'ethos.py', 'financial_phrasebank.py', 'glue_cola.py', 'glue_mnli.py']\n",
      "Process 3: Processing empathetic_dialogues.py ...\n",
      "Process 7 is handling the following tasks: ['onestop_english.py', 'paws.py', 'poem_sentiment.py', 'rotten_tomatoes.py', 'scicite.py']\n",
      "Process 7: Processing onestop_english.py ...\n",
      "Process 5 is handling the following tasks: ['glue_wnli.py', 'google_wellformed_query.py', 'hate_speech18.py', 'hate_speech_offensive.py', 'hatexplain.py']\n",
      "Process 5: Processing glue_wnli.py ...\n",
      "Process 8 is handling the following tasks: ['scitail.py', 'sick.py', 'sms_spam.py', 'superglue_cb.py', 'superglue_rte.py']\n",
      "Process 8: Processing scitail.py ...\n",
      "Process 9 is handling the following tasks: ['superglue_wic.py', 'superglue_wsc.py', 'tab_fact.py', 'trec.py', 'trec_finegrained.py']\n",
      "Process 9: Processing superglue_wic.py ...\n",
      "Process 6 is handling the following tasks: ['health_fact.py', 'imdb.py', 'kilt_fever.py', 'liar.py', 'medical_questions_pairs.py']\n",
      "Process 6: Processing health_fact.py ...\n",
      "Process 10 is handling the following tasks: ['tweet_eval.py', 'wiki_auto.py', 'wiki_qa.py', 'yahoo_answers_topics.py', 'yelp_polarity.py']\n",
      "Process 10: Processing tweet_eval.py ...\n",
      "Process 4 is handling the following tasks: ['glue_mrpc.py', 'glue_qnli.py', 'glue_qqp.py', 'glue_rte.py', 'glue_sst2.py']\n",
      "Process 4: Processing glue_mrpc.py ...\n",
      "Process 3: Processing empathetic_dialogues.py ... [Failed]\n",
      "Process 3: Processing ethos.py ...\n",
      "Process 5: Processing glue_wnli.py ... [Success]\n",
      "Process 5: Processing google_wellformed_query.py ...\n",
      "Process 7: Processing onestop_english.py ... [Success]\n",
      "Process 7: Processing paws.py ...\n",
      "Process 2: Processing climate_fever.py ... [Success]\n",
      "Process 2: Processing dbpedia_14.py ...\n",
      "Process 4: Processing glue_mrpc.py ... [Success]\n",
      "Process 4: Processing glue_qnli.py ...\n",
      "Process 1: Processing ade_classification.py ... [Success]\n",
      "Process 1: Processing agnews.py ...\n",
      "Process 9: Processing superglue_wic.py ... [Success]\n",
      "Process 9: Processing superglue_wsc.py ...\n",
      "Process 6: Processing health_fact.py ... [Success]\n",
      "Process 6: Processing imdb.py ...\n",
      "Process 2: Processing dbpedia_14.py ... [Failed]\n",
      "Process 2: Processing discovery.py ...\n",
      "Process 8: Processing scitail.py ... [Success]\n",
      "Process 8: Processing sick.py ...\n",
      "Process 3: Processing ethos.py ... [Success]\n",
      "Process 3: Processing financial_phrasebank.py ...\n",
      "Process 3: Processing financial_phrasebank.py ... [Failed]\n",
      "Process 3: Processing glue_cola.py ...\n",
      "Process 9: Processing superglue_wsc.py ... [Success]\n",
      "Process 9: Processing tab_fact.py ...\n",
      "Process 5: Processing google_wellformed_query.py ... [Success]\n",
      "Process 5: Processing hate_speech18.py ...\n",
      "Process 8: Processing sick.py ... [Success]\n",
      "Process 8: Processing sms_spam.py ...\n",
      "Process 3: Processing glue_cola.py ... [Success]\n",
      "Process 3: Processing glue_mnli.py ...\n",
      "Process 7: Processing paws.py ... [Success]\n",
      "Process 7: Processing poem_sentiment.py ...\n",
      "Process 1: Processing agnews.py ... [Success]\n",
      "Process 1: Processing amazon_polarity.py ...\n",
      "Process 4: Processing glue_qnli.py ... [Success]\n",
      "Process 4: Processing glue_qqp.py ...\n",
      "Process 1: Processing amazon_polarity.py ... [Failed]\n",
      "Process 1: Processing anli.py ...\n",
      "Process 8: Processing sms_spam.py ... [Success]\n",
      "Process 8: Processing superglue_cb.py ...\n",
      "Process 7: Processing poem_sentiment.py ... [Success]\n",
      "Process 7: Processing rotten_tomatoes.py ...\n",
      "Process 10: Processing tweet_eval.py ... [Success]\n",
      "Process 10: Processing wiki_auto.py ...\n",
      "Process 10: Processing wiki_auto.py ... [Failed]\n",
      "Process 10: Processing wiki_qa.py ...\n",
      "Process 8: Processing superglue_cb.py ... [Success]\n",
      "Process 8: Processing superglue_rte.py ...\n",
      "Process 7: Processing rotten_tomatoes.py ... [Success]\n",
      "Process 7: Processing scicite.py ...\n",
      "Process 1: Processing anli.py ... [Success]\n",
      "Process 1: Processing circa.py ...\n",
      "Process 10: Processing wiki_qa.py ... [Success]\n",
      "Process 10: Processing yahoo_answers_topics.py ...\n",
      "Process 8: Processing superglue_rte.py ... [Success]\n",
      "Process 10: Processing yahoo_answers_topics.py ... [Failed]\n",
      "Process 10: Processing yelp_polarity.py ...\n",
      "Process 7: Processing scicite.py ... [Success]\n",
      "Process 1: Processing circa.py ... [Success]\n",
      "Process 4: Processing glue_qqp.py ... [Success]\n",
      "Process 4: Processing glue_rte.py ...\n",
      "Process 3: Processing glue_mnli.py ... [Success]\n",
      "Process 4: Processing glue_rte.py ... [Success]\n",
      "Process 4: Processing glue_sst2.py ...\n",
      "Process 4: Processing glue_sst2.py ... [Success]\n",
      "Process 10: Processing yelp_polarity.py ... [Success]\n",
      "Process 2: Processing discovery.py ... [Success]\n",
      "Process 2: Processing emo.py ...\n",
      "Process 2: Processing emo.py ... [Success]\n",
      "Process 2: Processing emotion.py ...\n",
      "Process 2: Processing emotion.py ... [Failed]\n",
      "Process 5: Processing hate_speech18.py ... [Success]\n",
      "Process 5: Processing hate_speech_offensive.py ...\n",
      "Process 5: Processing hate_speech_offensive.py ... [Success]\n",
      "Process 5: Processing hatexplain.py ...\n",
      "Process 5: Processing hatexplain.py ... [Success]\n",
      "Process 9: Processing tab_fact.py ... [Success]\n",
      "Process 9: Processing trec.py ...\n",
      "Process 9: Processing trec.py ... [Success]\n",
      "Process 9: Processing trec_finegrained.py ...\n",
      "Process 9: Processing trec_finegrained.py ... [Success]\n",
      "Process 6: Processing imdb.py ... [Success]\n",
      "Process 6: Processing kilt_fever.py ...\n",
      "Process 6: Processing kilt_fever.py ... [Failed]\n",
      "Process 6: Processing liar.py ...\n",
      "Process 6: Processing liar.py ... [Success]\n",
      "Process 6: Processing medical_questions_pairs.py ...\n",
      "Process 6: Processing medical_questions_pairs.py ... [Success]\n",
      "Please try the following tasks later by running individual files: ['amazon_polarity.py', 'empathetic_dialogues.py', 'financial_phrasebank.py', 'wiki_auto.py', 'yahoo_answers_topics.py', 'dbpedia_14.py', 'emotion.py', 'kilt_fever.py']\n"
     ]
    }
   ],
   "source": [
    "!bash zero_para_download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180bfa05-40c1-4ce8-989b-379113e33ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/scripts/../entail2/runner/runner.py\", line 523, in <module>\n",
      "    runner = Runner(args=args)\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/scripts/../entail2/runner/runner.py\", line 81, in __init__\n",
      "    self.chain_train_loader = Chain_dataloader(\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/entail2/dataloader/chain_dataset.py\", line 82, in __init__\n",
      "    self.loaders = [\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/entail2/dataloader/chain_dataset.py\", line 85, in <listcomp>\n",
      "    if f(batch_size, tokenizer, use_sampler, training_shots)[0] is not None\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/entail2/dataloader/gym2entail_multitask.py\", line 111, in gym\n",
      "    train_dataset = GymDataset(\"train\", training_shots, tokenizer)\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/entail2/dataloader/gym2entail_multitask.py\", line 105, in __init__\n",
      "    super(GymDataset, self).__init__(\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/entail2/dataloader/base.py\", line 136, in __init__\n",
      "    self.mlabels = [\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/entail2/dataloader/base.py\", line 136, in <listcomp>\n",
      "    self.mlabels = [\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/entail2/dataloader/gym2entail_multitask.py\", line 72, in read_dataset\n",
      "    label_dic = get_label_dic()\n",
      "  File \"/scratch/gmosya/2023.eacl-main.142.software/ConEntail-main/entail2/dataloader/gym2entail_multitask.py\", line 49, in get_label_dic\n",
      "    with open(TRAIN, \"r\") as f_train:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'raw_data/gym/train-multi-ufsl_tasks-128.json'\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python ../entail2/runner/runner.py \\\n",
    "--learning_rate 1e-5 \\\n",
    "--warmup_ratio 0.06 \\\n",
    "--train_batch_size 32 \\\n",
    "--num_train_epochs 10 \\\n",
    "--bert_name bert \\\n",
    "--model_name entail2 \\\n",
    "--use_sampler \\\n",
    "--mode train;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
